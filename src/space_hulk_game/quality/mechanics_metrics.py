"""
Quality metrics for GameMechanics evaluation.

This module defines measurable quality criteria for game mechanics (PRD) documents
generated by the Space Hulk Game crew, including completeness, clarity, and balance.
"""

import logging
from dataclasses import dataclass
from typing import Any

import yaml

logger = logging.getLogger(__name__)


@dataclass
class MechanicsMetrics:
    """
    Quality metrics for evaluating game mechanics/PRD content.

    Attributes:
        has_combat_system: Whether combat mechanics are described
        has_movement_system: Whether movement mechanics are described
        has_inventory_system: Whether inventory mechanics are described
        has_progression_system: Whether character progression is described
        total_systems: Total number of game systems described
        systems_with_rules: Number of systems with clear rules
        completeness_percentage: Percentage of expected systems present
        average_rule_clarity: Average clarity score for rules
        has_balance_notes: Whether difficulty/balance is discussed
        min_systems: Minimum required systems (default: 3)
    """

    # Measured values
    has_combat_system: bool = False
    has_movement_system: bool = False
    has_inventory_system: bool = False
    has_progression_system: bool = False
    total_systems: int = 0
    systems_with_rules: int = 0
    completeness_percentage: float = 0.0
    average_rule_clarity: float = 0.0
    has_balance_notes: bool = False

    # Thresholds
    min_systems: int = 3
    min_completeness: float = 60.0  # 60% of expected systems
    min_clarity: float = 6.0  # Out of 10.0

    @classmethod
    def from_yaml_content(cls, yaml_content: str) -> "MechanicsMetrics":
        """
        Create MechanicsMetrics from YAML content string.

        Args:
            yaml_content: YAML string containing PRD/mechanics data

        Returns:
            MechanicsMetrics instance with measured values
        """
        try:
            # Handle markdown-wrapped YAML
            content = yaml_content.strip()
            if content.startswith("```"):
                lines = content.split("\n")
                content = "\n".join(lines[1:-1])

            data = yaml.safe_load(content)
            return cls.from_dict(data)
        except Exception as e:
            raise ValueError(f"Failed to parse YAML content: {e}") from e

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "MechanicsMetrics":
        """
        Create MechanicsMetrics from a dictionary (parsed YAML).

        Args:
            data: Dictionary containing PRD/mechanics data

        Returns:
            MechanicsMetrics instance with measured values
        """
        metrics = cls()

        # Get mechanics/systems section
        mechanics = data.get("mechanics", data)
        systems = mechanics.get("systems", {})

        # If no explicit systems section, analyze the entire document
        if not systems:
            systems = mechanics

        # Check for specific core systems
        metrics.has_combat_system = cls._has_system(systems, "combat")
        metrics.has_movement_system = cls._has_system(systems, "movement")
        metrics.has_inventory_system = cls._has_system(systems, "inventory")
        metrics.has_progression_system = cls._has_system(systems, "progression")

        # Count total systems
        metrics.total_systems = cls._count_systems(systems)

        # Count systems with clear rules
        metrics.systems_with_rules, clarity_scores = cls._analyze_rule_clarity(systems)

        # Calculate completeness (out of 5 expected core systems)
        expected_systems = 5
        present_systems = sum(
            [
                metrics.has_combat_system,
                metrics.has_movement_system,
                metrics.has_inventory_system,
                metrics.has_progression_system,
                metrics.total_systems > 0,  # At least one other system
            ]
        )
        metrics.completeness_percentage = (present_systems / expected_systems) * 100.0

        # Calculate average clarity
        if clarity_scores:
            metrics.average_rule_clarity = sum(clarity_scores) / len(clarity_scores)

        # Check for balance/difficulty notes
        metrics.has_balance_notes = cls._has_balance_notes(mechanics)

        return metrics

    @staticmethod
    def _has_system(systems: dict[str, Any], system_name: str) -> bool:
        """
        Check if a specific system is described.

        Args:
            systems: Dictionary of game systems
            system_name: Name of system to check for

        Returns:
            True if system is present and described
        """
        # Check for direct key
        if system_name in systems:
            return True

        # Check for variations
        variations = [
            system_name,
            f"{system_name}_system",
            f"{system_name}_mechanics",
            system_name.title(),
        ]

        for var in variations:
            if var in systems:
                return True

        # Check in nested structures
        for key, value in systems.items():
            if system_name.lower() in key.lower():
                return True
            if isinstance(value, str) and system_name.lower() in value.lower():
                # System mentioned in description
                if len(value) >= 50:  # Substantial mention
                    return True

        return False

    @staticmethod
    def _count_systems(systems: dict[str, Any]) -> int:
        """
        Count total number of game systems described.

        Args:
            systems: Dictionary of game systems

        Returns:
            Number of systems
        """
        count = 0

        # Count top-level system keys
        system_keywords = [
            "combat",
            "movement",
            "inventory",
            "progression",
            "health",
            "stamina",
            "skill",
            "puzzle",
            "dialogue",
            "stealth",
            "resource",
            "crafting",
            "trading",
            "reputation",
            "time",
            "environment",
        ]

        for key in systems.keys():
            # Check if key contains a system keyword
            key_lower = key.lower()
            if any(keyword in key_lower for keyword in system_keywords):
                count += 1
            # Or if it's a substantial section
            elif isinstance(systems[key], (dict, list)):
                count += 1

        return count

    @staticmethod
    def _analyze_rule_clarity(systems: dict[str, Any]) -> tuple:
        """
        Analyze clarity of rules for each system.

        Args:
            systems: Dictionary of game systems

        Returns:
            Tuple of (count of systems with clear rules, list of clarity scores)
        """
        clear_count = 0
        clarity_scores = []

        for _key, value in systems.items():
            if not isinstance(value, (dict, str)):
                continue

            # Analyze this system
            score = 0.0

            if isinstance(value, dict):
                # Check for rules/description
                has_rules = "rules" in value or "description" in value
                has_examples = "example" in value or "examples" in value

                # Get text content
                text = str(value)
                word_count = len(text.split())

                # Scoring (adjusted for realistic content)
                if has_rules or has_examples:
                    score += 4.0  # Having rules/description is most important
                if word_count >= 50:
                    score += 3.0  # Decent length
                elif word_count >= 20:
                    score += 2.0

                # Structured data bonus
                if len(value) >= 2:
                    score += 3.0

            elif isinstance(value, str):
                word_count = len(value.split())

                # Scoring based on length
                if word_count >= 50:
                    score += 7.0
                elif word_count >= 20:
                    score += 5.0
                elif word_count >= 10:
                    score += 3.0

                # Check for structured language
                if any(word in value.lower() for word in ["must", "should", "can", "when", "if"]):
                    score += 2.0

            clarity_scores.append(min(score, 10.0))

            if score >= 6.0:
                clear_count += 1

        return clear_count, clarity_scores

    @staticmethod
    def _has_balance_notes(mechanics: dict[str, Any]) -> bool:
        """
        Check if balance or difficulty is discussed.

        Args:
            mechanics: Mechanics dictionary

        Returns:
            True if balance is mentioned
        """
        balance_keywords = [
            "balance",
            "difficulty",
            "challenge",
            "fair",
            "balanced",
            "easy",
            "hard",
            "moderate",
            "scaling",
            "progression curve",
        ]

        # Convert to string for searching
        mechanics_str = str(mechanics).lower()

        return any(keyword in mechanics_str for keyword in balance_keywords)

    def passes_threshold(self) -> bool:
        """
        Check if the mechanics metrics pass all quality thresholds.

        Returns:
            True if all thresholds are met, False otherwise
        """
        return (
            self.total_systems >= self.min_systems
            and self.completeness_percentage >= self.min_completeness
            and self.average_rule_clarity >= self.min_clarity
        )

    def get_failures(self) -> list[str]:
        """
        Get list of failed quality checks.

        Returns:
            List of failure messages for metrics that don't meet thresholds
        """
        failures = []

        if self.total_systems < self.min_systems:
            failures.append(
                f"Insufficient game systems: {self.total_systems} " f"(minimum: {self.min_systems})"
            )

        if self.completeness_percentage < self.min_completeness:
            failures.append(
                f"Core systems incomplete: {self.completeness_percentage:.1f}% "
                f"(minimum: {self.min_completeness}%)"
            )

        if self.average_rule_clarity < self.min_clarity:
            failures.append(
                f"Rules not clear enough: avg score {self.average_rule_clarity:.1f}/10 "
                f"(minimum: {self.min_clarity})"
            )

        # Warnings for missing core systems
        missing_core = []
        if not self.has_combat_system:
            missing_core.append("combat")
        if not self.has_movement_system:
            missing_core.append("movement")
        if not self.has_inventory_system:
            missing_core.append("inventory")

        if missing_core:
            failures.append(f"Warning: Missing core systems: {', '.join(missing_core)}")

        return failures

    def get_score(self) -> float:
        """
        Calculate overall quality score (0.0 to 10.0).

        Returns:
            Quality score based on met criteria
        """
        score = 0.0

        # Total systems (2 points)
        if self.total_systems >= self.min_systems:
            score += 2.0
        elif self.total_systems > 0:
            score += 2.0 * (self.total_systems / self.min_systems)

        # Completeness (3 points)
        score += 3.0 * (self.completeness_percentage / 100.0)

        # Rule clarity (3 points)
        score += 3.0 * (self.average_rule_clarity / 10.0)

        # Core systems (1.5 points total)
        core_systems = sum(
            [
                self.has_combat_system,
                self.has_movement_system,
                self.has_inventory_system,
            ]
        )
        score += 1.5 * (core_systems / 3.0)

        # Balance notes (0.5 points)
        if self.has_balance_notes:
            score += 0.5

        return min(score, 10.0)

    def to_dict(self) -> dict[str, Any]:
        """
        Convert metrics to dictionary for serialization.

        Returns:
            Dictionary representation of metrics
        """
        return {
            "has_combat_system": self.has_combat_system,
            "has_movement_system": self.has_movement_system,
            "has_inventory_system": self.has_inventory_system,
            "has_progression_system": self.has_progression_system,
            "total_systems": self.total_systems,
            "systems_with_rules": self.systems_with_rules,
            "completeness_percentage": round(self.completeness_percentage, 1),
            "average_rule_clarity": round(self.average_rule_clarity, 2),
            "has_balance_notes": self.has_balance_notes,
            "passes_threshold": self.passes_threshold(),
            "score": self.get_score(),
            "failures": self.get_failures(),
        }
